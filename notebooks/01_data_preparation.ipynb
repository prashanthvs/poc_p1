{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation Notebook\n",
        "\n",
        "This notebook handles document loading, preprocessing, and vector index creation for the Maverick RAG system.\n",
        "\n",
        "## Features\n",
        "- Document loading from local files or Unity Catalog volumes\n",
        "- Text chunking and preprocessing\n",
        "- FAISS index creation (local development)\n",
        "- Databricks vector search setup (enterprise deployment)\n",
        "- Delta Lake table creation\n",
        "- Configuration validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Add src to path for imports\n",
        "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Import our modules\n",
        "from utils import config_manager\n",
        "from rag.ingest import load_documents, build_index, build_databricks_vector_index\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display current configuration\n",
        "config_summary = config_manager.get_config_summary()\n",
        "print(\"üìã Current Configuration:\")\n",
        "for section, config in config_summary.items():\n",
        "    print(f\"\\n{section.upper()}:\")\n",
        "    for key, value in config.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# Validate configuration\n",
        "validation = config_manager.validate_config()\n",
        "print(f\"\\nüîç Configuration Validation: {'‚úÖ Valid' if validation['valid'] else '‚ùå Invalid'}\")\n",
        "\n",
        "if validation['errors']:\n",
        "    print(\"\\n‚ùå Errors:\")\n",
        "    for error in validation['errors']:\n",
        "        print(f\"  - {error}\")\n",
        "\n",
        "if validation['warnings']:\n",
        "    print(\"\\n‚ö†Ô∏è Warnings:\")\n",
        "    for warning in validation['warnings']:\n",
        "        print(f\"  - {warning}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Document Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load documents\n",
        "docs_dir = config_manager.data.docs_dir\n",
        "print(f\"üìÅ Loading documents from: {docs_dir}\")\n",
        "\n",
        "try:\n",
        "    documents = load_documents(docs_dir)\n",
        "    print(f\"‚úÖ Loaded {len(documents)} documents\")\n",
        "    \n",
        "    # Display document information\n",
        "    if documents:\n",
        "        print(\"\\nüìÑ Document Summary:\")\n",
        "        for i, doc in enumerate(documents[:5]):  # Show first 5\n",
        "            source = doc.metadata.get('source', 'Unknown')\n",
        "            content_preview = doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content\n",
        "            print(f\"  {i+1}. Source: {source}\")\n",
        "            print(f\"     Content: {content_preview}\")\n",
        "            print(f\"     Length: {len(doc.page_content)} characters\")\n",
        "            print()\n",
        "        \n",
        "        if len(documents) > 5:\n",
        "            print(f\"  ... and {len(documents) - 5} more documents\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No documents found\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading documents: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local FAISS Index Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create FAISS index for local development\n",
        "if not config_manager.data.use_databricks:\n",
        "    print(\"üèóÔ∏è Creating FAISS index for local development...\")\n",
        "    \n",
        "    try:\n",
        "        index_path = build_index(\n",
        "            docs_dir=config_manager.data.docs_dir,\n",
        "            index_dir=config_manager.data.index_dir,\n",
        "            use_databricks=False\n",
        "        )\n",
        "        print(f\"‚úÖ FAISS index created at: {index_path}\")\n",
        "        \n",
        "        # Test the index\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "        from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "        \n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=config_manager.embedding.model_name\n",
        "        )\n",
        "        \n",
        "        store = FAISS.load_local(\n",
        "            config_manager.data.index_dir, \n",
        "            embeddings, \n",
        "            allow_dangerous_deserialization=True\n",
        "        )\n",
        "        \n",
        "        print(f\"üìä Index contains {store.index.ntotal} vectors\")\n",
        "        \n",
        "        # Test similarity search\n",
        "        test_query = \"What is the project charter about?\"\n",
        "        results = store.similarity_search(test_query, k=3)\n",
        "        \n",
        "        print(f\"\\nüîç Test query: '{test_query}'\")\n",
        "        print(\"üìÑ Top 3 results:\")\n",
        "        for i, result in enumerate(results):\n",
        "            print(f\"  {i+1}. {result.page_content[:150]}...\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating FAISS index: {e}\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping FAISS index creation (Databricks mode enabled)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
