# configuration.yaml
app:
  server_name: "0.0.0.0"
  server_port: 8081
  title: "Maverick RAG"

llm:
  provider: "ollama" # Options: together, openai, ollama, databricks
  model: "llama3.1:8b"
  temperature: 0.2
  timeout: 60
  providers:
    together:
      api_key: "your_together_api_key_here"
      base_url: "https://api.together.xyz/v1"
    openai:
      api_key: "your_openai_api_key_here"
    ollama:
      api_key: "ollama"
      base_url: "http://localhost:11434/v1"

embedding:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  provider: "huggingface"

data:
  docs_dir: "data/docs/sample_data"
  index_dir: "data/index"
  use_databricks: false

databricks:
  workspace_url: "your_workspace_url.databricks.com"
  access_token: "your_databricks_access_token"
  catalog: "main"
  schema: "default"
  volume: "source_data"
  vector_search_endpoint: "your_vector_search_endpoint"
  model_serving_endpoint: "your_model_serving_endpoint"